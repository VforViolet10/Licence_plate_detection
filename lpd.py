# -*- coding: utf-8 -*-
"""lpd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zjp-kSIdnz7sdr99oxXcb0k6Mtvk13JP
"""

from google.colab import files
files.upload()  # ⬆️ upload your kaggle.json when prompted

import os
import cv2
import xml.etree.ElementTree as ET
import random
import zipfile
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# ============================================
# CONFIG
# ============================================
KAGGLE_DATASET = "andrewmvd/car-plate-detection"
DATA_DIR = "car_plate_detection"
OUT_DIR = "dataset"
random.seed(42)

# ============================================
# STEP 1: Configure Kaggle API and Download dataset
# ============================================
print("⚙️ Configuring Kaggle API...")
# Ensure the .kaggle directory exists
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
# Move the uploaded kaggle.json to the correct location
kaggle_json_path = os.path.expanduser("~/.kaggle/kaggle.json")
if os.path.exists("kaggle.json"):
    os.rename("kaggle.json", kaggle_json_path)
    if os.path.exists(kaggle_json_path):
        # Set permissions for the kaggle.json file
        os.chmod(kaggle_json_path, 0o600)
        print("✅ Kaggle API configured.")
    else:
        print("❌ Failed to move kaggle.json to the correct location.")
        raise SystemExit
else:
    print("❌ kaggle.json not found in the current directory after upload. Please upload your kaggle.json file again.")
    raise SystemExit


print("📥 Downloading dataset...")
os.system(f"kaggle datasets download -d {KAGGLE_DATASET} -p .")

zip_file = "car-plate-detection.zip"
if os.path.exists(zip_file):
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(DATA_DIR)
    print("✅ Dataset extracted.")
else:
    print("❌ Download failed. Please ensure Kaggle API is configured and the dataset exists.")
    raise SystemExit

# ============================================
# STEP 2: Prepare folders
# ============================================
train_plate = os.path.join(OUT_DIR, "train/plate")
train_no = os.path.join(OUT_DIR, "train/no_plate")
val_plate = os.path.join(OUT_DIR, "val/plate")
val_no = os.path.join(OUT_DIR, "val/no_plate")

for d in [train_plate, train_no, val_plate, val_no]:
    os.makedirs(d, exist_ok=True)

IMG_DIR = os.path.join(DATA_DIR, "images")
ANNOT_DIR = os.path.join(DATA_DIR, "annotations")

# ============================================
# STEP 3: Extract plate crops and no-plate crops
# ============================================
plate_images = []
no_plate_images = []

print("🔍 Generating crops...")
for xml_file in tqdm(os.listdir(ANNOT_DIR)):
    if not xml_file.endswith(".xml"):
        continue

    xml_path = os.path.join(ANNOT_DIR, xml_file)
    tree = ET.parse(xml_path)
    root = tree.getroot()

    img_file = root.find("filename").text
    img_path = os.path.join(IMG_DIR, img_file)
    img = cv2.imread(img_path)
    if img is None:
        continue

    h, w = img.shape[:2]

    # ---- Extract plate crops ----
    for obj in root.findall("object"):
        bbox = obj.find("bndbox")
        x1 = int(float(bbox.find("xmin").text))
        y1 = int(float(bbox.find("ymin").text))
        x2 = int(float(bbox.find("xmax").text))
        y2 = int(float(bbox.find("ymax").text))
        plate_crop = img[y1:y2, x1:x2]
        if plate_crop.size > 0:
            fname = f"{os.path.splitext(img_file)[0]}_plate.jpg"
            save_path = os.path.join(OUT_DIR, "all_plate_" + fname)
            cv2.imwrite(save_path, plate_crop)
            plate_images.append(save_path)

    # ---- Generate random background crops (no_plate) ----
    for i in range(2):
        rw = random.randint(80, 150)
        rh = random.randint(40, 80)
        rx = random.randint(0, max(1, w - rw - 1))
        ry = random.randint(0, max(1, h - rh - 1))
        crop = img[ry:ry+rh, rx:rx+rw]
        if crop.size > 0:
            fname = f"{os.path.splitext(img_file)[0]}_no_{i}.jpg"
            save_path = os.path.join(OUT_DIR, "all_no_" + fname)
            cv2.imwrite(save_path, crop)
            no_plate_images.append(save_path)

print(f"✅ Total plate crops: {len(plate_images)}")
print(f"✅ Total no-plate crops: {len(no_plate_images)}")

# ============================================
# STEP 4: Split into train/val (80/20)
# ============================================
plate_train, plate_val = train_test_split(plate_images, test_size=0.2, random_state=42)
no_train, no_val = train_test_split(no_plate_images, test_size=0.2, random_state=42)

def move_files(file_list, dest_folder):
    for f in file_list:
        if os.path.exists(f):
            fname = os.path.basename(f)
            cv2.imwrite(os.path.join(dest_folder, fname), cv2.imread(f))

move_files(plate_train, train_plate)
move_files(no_train, train_no)
move_files(plate_val, val_plate)
move_files(no_val, val_no)

print(f"\n✅ Dataset ready at '{OUT_DIR}/' structure:")
print(f"  - train/plate : {len(plate_train)} images")
print(f"  - train/no_plate : {len(no_train)} images")
print(f"  - val/plate : {len(plate_val)} images")
print(f"  - val/no_plate : {len(no_val)} images")

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau

# ======================================
# CONFIG
# ======================================
DATA_DIR = "dataset"
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10
MODEL_SAVE = "plate_classifier_mobilenetv2.h5"

# ======================================
# DATA GENERATORS
# ======================================
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=8,
    width_shift_range=0.08,
    height_shift_range=0.08,
    shear_range=0.08,
    zoom_range=0.08,
    horizontal_flip=True,
    fill_mode="nearest"
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    os.path.join(DATA_DIR, "train"),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary"
)

val_gen = val_datagen.flow_from_directory(
    os.path.join(DATA_DIR, "val"),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary"
)

# ======================================
# MODEL
# ======================================
base = MobileNetV2(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), include_top=False, weights="imagenet")
x = base.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
pred = Dense(1, activation="sigmoid")(x)

model = Model(inputs=base.input, outputs=pred)

for layer in base.layers:
    layer.trainable = False

model.compile(optimizer=Adam(1e-3), loss="binary_crossentropy", metrics=["accuracy"])

callbacks = [
    ModelCheckpoint(MODEL_SAVE, save_best_only=True, monitor="val_accuracy", mode="max", verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, verbose=1)
]

print("🚀 Training started...")
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    callbacks=callbacks
)

print("\n✅ Model saved as:", MODEL_SAVE)

import cv2
import numpy as np
from tensorflow.keras.models import load_model
from google.colab.patches import cv2_imshow

# ======================================
# CONFIG
# ======================================
MODEL_PATH = "/content/plate_classifier_mobilenetv2.h5"
IMG_PATH = "/content/Cars44.png"
IMG_SIZE = (224, 224)

# ======================================
# LOAD MODEL
# ======================================
print("Loading model...")
model = load_model(MODEL_PATH)
print("Model loaded successfully!")

# ======================================
# LOAD AND PREPROCESS IMAGE
# ======================================
img = cv2.imread(IMG_PATH)
if img is None:
    raise FileNotFoundError(f"Image not found at {IMG_PATH}")

# Keep original for display
orig = img.copy()

# Resize and normalize for model
img_resized = cv2.resize(img, IMG_SIZE)
img_resized = img_resized.astype("float32") / 255.0
img_resized = np.expand_dims(img_resized, axis=0)

# ======================================
# PREDICT
# ======================================
pred = model.predict(img_resized)[0][0]
label = "PLATE DETECTED" if pred > 0.5 else "NO PLATE"
color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)

# ======================================
# DISPLAY RESULT
# ======================================
cv2.putText(orig, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
cv2_imshow(orig) # Use cv2_imshow instead of cv2.imshow
cv2.waitKey(0)
cv2.destroyAllWindows()

print(f"🧠 Prediction: {label} (Confidence: {pred:.4f})")

import cv2
import numpy as np
from tensorflow.keras.models import load_model
from google.colab.patches import cv2_imshow

# ======================================
# CONFIG
# ======================================
MODEL_PATH = "plate_classifier_mobilenetv2.h5"
IMG_PATH = "/content/Cars16.png"
IMG_SIZE = (224, 224)

# ======================================
# LOAD MODEL
# ======================================
print("Loading model...")
model = load_model(MODEL_PATH)
print("Model loaded successfully!")

# ======================================
# LOAD AND PREPROCESS IMAGE
# ======================================
img = cv2.imread(IMG_PATH)
if img is None:
    raise FileNotFoundError(f"Image not found at {IMG_PATH}")

# Keep original for display
orig = img.copy()

# Resize and normalize for model
img_resized = cv2.resize(img, IMG_SIZE)
img_resized = img_resized.astype("float32") / 255.0
img_resized = np.expand_dims(img_resized, axis=0)

# ======================================
# PREDICT
# ======================================
pred = model.predict(img_resized)[0][0]
label = "PLATE DETECTED" if pred > 0.5 else "NO PLATE"
color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)

# ======================================
# DISPLAY RESULT
# ======================================
cv2.putText(orig, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
cv2_imshow(orig) # Use cv2_imshow instead of cv2.imshow
cv2.waitKey(0)
cv2.destroyAllWindows()

print(f"🧠 Prediction: {label} (Confidence: {pred:.4f})")

import cv2
import numpy as np
from tensorflow.keras.models import load_model
from google.colab.patches import cv2_imshow

# ======================================
# CONFIG
# ======================================
MODEL_PATH = "/content/plate_classifier_mobilenetv2.h5"
IMG_SIZE = (224, 224)

# Load trained model
print("📦 Loading model...")
model = load_model(MODEL_PATH)
print("✅ Model loaded successfully!")

# Start webcam
# NOTE: cv2.VideoCapture(0) typically accesses the default webcam.
# If you have multiple cameras or an external one, you might need to try
# different indices like 1, 2, etc.
# Webcam functionality is not directly supported in standard Colab
# environments without workarounds (e.g., ngrok or streaming).
# This code block will likely not work as expected in a standard Colab setup
# for live webcam feed unless you implement a streaming solution.
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("❌ Camera not detected! Live detection will not work in this environment.")
    # Exit the loop if camera is not opened to prevent errors
    # and provide feedback to the user.
    # You might want to handle this more gracefully depending on requirements.
    pass # Or sys.exit() if you want to stop execution entirely

print("🎥 Starting live detection... Press 'q' to quit.")

# Only attempt to process if the camera was opened
if cap.isOpened():
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Resize frame for prediction
        img = cv2.resize(frame, IMG_SIZE)
        img = img.astype("float32") / 255.0
        img = np.expand_dims(img, axis=0)

        # Predict
        pred = model.predict(img)[0][0]
        label = "PLATE DETECTED ✅" if pred > 0.5 else "NO PLATE ❌"
        color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)

        # Display result
        cv2.putText(frame, label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
        cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow

        # Press 'q' to quit
        # waitKey(1) gives a 1ms delay, allowing the display to update
        # 0xFF is a mask to get the lower 8 bits of the key code,
        # which is necessary for cross-platform compatibility.
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("Exiting...")
else:
    print("Skipping live detection due to camera not being detected.")